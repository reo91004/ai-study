{
	"cells": [
		{
			"cell_type": "markdown",
			"id": "intro_cnn",
			"metadata": {},
			"source": [
				"# 합성곱 신경망(CNN)을 이용한 이미지 분류\n",
				"\n",
				"**학습 목표:**\n",
				"- 이미지 데이터의 공간적 특징(spatial feature)을 효과적으로 학습하는 **합성곱 신경망(CNN)**의 구조를 이해합니다.\n",
				"- CNN의 핵심 구성 요소인 **합성곱(Convolution)**, **활성화 함수(ReLU)**, **풀링(Pooling)** 계층의 역할과 동작 방식을 학습합니다.\n",
				"- **PyTorch**를 사용하여 직접 CNN 모델을 구축하고, 10개의 클래스로 구성된 **CIFAR-10** 이미지 데이터셋을 분류하는 실습을 진행합니다.\n",
				"- **데이터 증강(Data Augmentation)**을 통해 모델의 일반화 성능을 높이는 기법을 적용합니다."
			]
		},
		{
			"cell_type": "code",
			"id": "imports_cnn",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"source": [
				"import torch\n",
				"import torch.nn as nn\n",
				"import torch.optim as optim\n",
				"import torchvision\n",
				"import torchvision.transforms as transforms\n",
				"import matplotlib.pyplot as plt\n",
				"import numpy as np"
			]
		},
		{
			"cell_type": "markdown",
			"id": "config_cnn",
			"metadata": {},
			"source": ["### (1) 하이퍼파라미터 및 장치 설정"]
		},
		{
			"cell_type": "code",
			"id": "set_config_cnn",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"source": ["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "print(f'Using device: {device}')\n", "\n", "batch_size = 128\n", "learning_rate = 0.001\n", "epochs = 20"]
		},
		{
			"cell_type": "markdown",
			"id": "data_prep_cnn",
			"metadata": {},
			"source": [
				"### (2) 데이터 준비: CIFAR-10\n",
				"CIFAR-10 데이터셋은 `비행기, 자동차, 새, 고양이, 사슴, 개, 개구리, 말, 배, 트럭` 10개 클래스로 구성된 3x32x32 크기의 컬러 이미지입니다. 모델이 다양한 이미지에 강건해지도록, 훈련 데이터에만 **데이터 증강(Data Augmentation)** 기법(이미지를 무작위로 자르거나 뒤집기)을 적용합니다."
			]
		},
		{
			"cell_type": "code",
			"id": "load_data_cnn",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"source": [
				"# 훈련 데이터용 변환: 데이터 증강 포함\n",
				"transform_train = transforms.Compose([\n",
				"    transforms.RandomCrop(32, padding=4),\n",
				"    transforms.RandomHorizontalFlip(),\n",
				"    transforms.ToTensor(),\n",
				"    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # CIFAR-10 데이터의 평균과 표준편차\n",
				"])\n",
				"\n",
				"# 테스트 데이터용 변환: 데이터 증강 없음\n",
				"transform_test = transforms.Compose([\n",
				"    transforms.ToTensor(),\n",
				"    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
				"])\n",
				"\n",
				"train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
				"test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
				"\n",
				"train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
				"test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
				"\n",
				"classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
				"\n",
				"# 데이터 샘플 시각화\n",
				"def imshow(img):\n",
				"    img = img / 2 + 0.5     # unnormalize\n",
				"    npimg = img.numpy()\n",
				"    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
				"    plt.show()\n",
				"\n",
				"dataiter = iter(train_loader)\n",
				"images, labels = next(dataiter)\n",
				"imshow(torchvision.utils.make_grid(images[:8]))\n",
				"print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "model_def_cnn",
			"metadata": {},
			"source": [
				"### (3) 모델 정의: BasicCNN\n",
				"두 개의 합성곱 블록(Conv-ReLU-Pool)과 세 개의 완전 연결 계층(MLP)으로 구성된 간단한 CNN 모델을 정의합니다. 합성곱 층은 이미지의 특징을 추출하고, 풀링 층은 특징 맵의 크기를 줄여 계산 효율성을 높이고 주요 특징을 강조하는 역할을 합니다."
			]
		},
		{
			"cell_type": "code",
			"id": "create_model_cnn",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"source": [
				"class BasicCNN(nn.Module):\n",
				"    def __init__(self):\n",
				"        super(BasicCNN, self).__init__()\n",
				"        self.conv_block1 = nn.Sequential(\n",
				"            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
				"            nn.ReLU(),\n",
				"            nn.MaxPool2d(kernel_size=2, stride=2)\n",
				"        )\n",
				"        self.conv_block2 = nn.Sequential(\n",
				"            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
				"            nn.ReLU(),\n",
				"            nn.MaxPool2d(kernel_size=2, stride=2)\n",
				"        )\n",
				"        self.classifier = nn.Sequential(\n",
				"            nn.Flatten(),\n",
				"            nn.Linear(64 * 8 * 8, 512),\n",
				"            nn.ReLU(),\n",
				"            nn.Dropout(0.5),\n",
				"            nn.Linear(512, 10)\n",
				"        )\n",
				"\n",
				"    def forward(self, x):\n",
				"        x = self.conv_block1(x)\n",
				"        x = self.conv_block2(x)\n",
				"        x = self.classifier(x)\n",
				"        return x\n",
				"\n",
				"model = BasicCNN().to(device)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "loss_optim_cnn",
			"metadata": {},
			"source": [
				"### (4) 손실 함수, 옵티마이저, 학습률 스케줄러 설정\n",
				"- 옵티마이저는 `Adam`을 사용합니다.\n",
				"- `StepLR` 스케줄러는 특정 단계마다 학습률을 감소시켜, 훈련 후반부에 모델이 최적점에 더 안정적으로 수렴하도록 돕습니다."
			]
		},
		{
			"cell_type": "code",
			"id": "set_loss_optim_cnn",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"source": [
				"criterion = nn.CrossEntropyLoss()\n",
				"optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
				"scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # 7 에포크마다 학습률 0.1배 감소"
			]
		},
		{
			"cell_type": "markdown",
			"id": "train_section_cnn",
			"metadata": {},
			"source": ["### (5) 모델 훈련 및 평가"]
		},
		{
			"cell_type": "code",
			"id": "run_train_cnn",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"source": [
				"train_losses = []\n",
				"test_accuracies = []\n",
				"\n",
				"for epoch in range(epochs):\n",
				"    model.train()\n",
				"    running_loss = 0.0\n",
				"    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
				"        inputs, labels = inputs.to(device), labels.to(device)\n",
				"        \n",
				"        optimizer.zero_grad()\n",
				"        \n",
				"        outputs = model(inputs)\n",
				"        loss = criterion(outputs, labels)\n",
				"        loss.backward()\n",
				"        optimizer.step()\n",
				"        \n",
				"        running_loss += loss.item()\n",
				"    \n",
				"    train_losses.append(running_loss / len(train_loader))\n",
				"    scheduler.step() # 스케줄러 업데이트\n",
				"\n",
				"    # 에포크마다 테스트 정확도 확인\n",
				"    model.eval()\n",
				"    correct = 0\n",
				"    total = 0\n",
				"    with torch.no_grad():\n",
				"        for data in test_loader:\n",
				"            images, labels = data[0].to(device), data[1].to(device)\n",
				"            outputs = model(images)\n",
				"            _, predicted = torch.max(outputs.data, 1)\n",
				"            total += labels.size(0)\n",
				"            correct += (predicted == labels).sum().item()\n",
				"    \n",
				"    accuracy = 100 * correct / total\n",
				"    test_accuracies.append(accuracy)\n",
				"    print(f'Epoch [{epoch+1}/{epochs}], Loss: {train_losses[-1]:.4f}, Test Accuracy: {accuracy:.2f}%')"
			]
		},
		{
			"cell_type": "markdown",
			"id": "eval_section_cnn",
			"metadata": {},
			"source": ["### (6) 학습 과정 시각화"]
		},
		{
			"cell_type": "code",
			"id": "run_eval_cnn",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"source": [
				"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
				"\n",
				"ax1.plot(train_losses)\n",
				"ax1.set_title(\"Training Loss\")\n",
				"ax1.set_xlabel(\"Epoch\")\n",
				"ax1.set_ylabel(\"Loss\")\n",
				"\n",
				"ax2.plot(test_accuracies)\n",
				"ax2.set_title(\"Test Accuracy\")\n",
				"ax2.set_xlabel(\"Epoch\")\n",
				"ax2.set_ylabel(\"Accuracy (%)\")\n",
				"\n",
				"plt.show()"
			]
		}
	],
	"metadata": {},
	"nbformat": 4,
	"nbformat_minor": 5
}
